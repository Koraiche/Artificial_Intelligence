{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48771ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "os.environ['TFF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba8aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9a9373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0642b99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "[[[[0.23137255 0.24313726 0.24705882]\n",
      "   [0.16862746 0.18039216 0.1764706 ]\n",
      "   [0.19607843 0.1882353  0.16862746]\n",
      "   ...\n",
      "   [0.61960787 0.5176471  0.42352942]\n",
      "   [0.59607846 0.49019608 0.4       ]\n",
      "   [0.5803922  0.4862745  0.40392157]]\n",
      "\n",
      "  [[0.0627451  0.07843138 0.07843138]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.07058824 0.03137255 0.        ]\n",
      "   ...\n",
      "   [0.48235294 0.34509805 0.21568628]\n",
      "   [0.46666667 0.3254902  0.19607843]\n",
      "   [0.47843137 0.34117648 0.22352941]]\n",
      "\n",
      "  [[0.09803922 0.09411765 0.08235294]\n",
      "   [0.0627451  0.02745098 0.        ]\n",
      "   [0.19215687 0.10588235 0.03137255]\n",
      "   ...\n",
      "   [0.4627451  0.32941177 0.19607843]\n",
      "   [0.47058824 0.32941177 0.19607843]\n",
      "   [0.42745098 0.28627452 0.16470589]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8156863  0.6666667  0.3764706 ]\n",
      "   [0.7882353  0.6        0.13333334]\n",
      "   [0.7764706  0.6313726  0.10196079]\n",
      "   ...\n",
      "   [0.627451   0.52156866 0.27450982]\n",
      "   [0.21960784 0.12156863 0.02745098]\n",
      "   [0.20784314 0.13333334 0.07843138]]\n",
      "\n",
      "  [[0.7058824  0.54509807 0.3764706 ]\n",
      "   [0.6784314  0.48235294 0.16470589]\n",
      "   [0.7294118  0.5647059  0.11764706]\n",
      "   ...\n",
      "   [0.72156864 0.5803922  0.36862746]\n",
      "   [0.38039216 0.24313726 0.13333334]\n",
      "   [0.3254902  0.20784314 0.13333334]]\n",
      "\n",
      "  [[0.69411767 0.5647059  0.45490196]\n",
      "   [0.65882355 0.5058824  0.36862746]\n",
      "   [0.7019608  0.5568628  0.34117648]\n",
      "   ...\n",
      "   [0.84705883 0.72156864 0.54901963]\n",
      "   [0.5921569  0.4627451  0.32941177]\n",
      "   [0.48235294 0.36078432 0.28235295]]]\n",
      "\n",
      "\n",
      " [[[0.6039216  0.69411767 0.73333335]\n",
      "   [0.49411765 0.5372549  0.53333336]\n",
      "   [0.4117647  0.40784314 0.37254903]\n",
      "   ...\n",
      "   [0.35686275 0.37254903 0.2784314 ]\n",
      "   [0.34117648 0.3529412  0.2784314 ]\n",
      "   [0.30980393 0.31764707 0.27450982]]\n",
      "\n",
      "  [[0.54901963 0.627451   0.6627451 ]\n",
      "   [0.5686275  0.6        0.6039216 ]\n",
      "   [0.49019608 0.49019608 0.4627451 ]\n",
      "   ...\n",
      "   [0.3764706  0.3882353  0.30588236]\n",
      "   [0.3019608  0.3137255  0.24313726]\n",
      "   [0.2784314  0.28627452 0.23921569]]\n",
      "\n",
      "  [[0.54901963 0.60784316 0.6431373 ]\n",
      "   [0.54509807 0.57254905 0.58431375]\n",
      "   [0.4509804  0.4509804  0.4392157 ]\n",
      "   ...\n",
      "   [0.30980393 0.32156864 0.2509804 ]\n",
      "   [0.26666668 0.27450982 0.21568628]\n",
      "   [0.2627451  0.27058825 0.21568628]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.6862745  0.654902   0.6509804 ]\n",
      "   [0.6117647  0.6039216  0.627451  ]\n",
      "   [0.6039216  0.627451   0.6666667 ]\n",
      "   ...\n",
      "   [0.16470589 0.13333334 0.14117648]\n",
      "   [0.23921569 0.20784314 0.22352941]\n",
      "   [0.3647059  0.3254902  0.35686275]]\n",
      "\n",
      "  [[0.64705884 0.6039216  0.5019608 ]\n",
      "   [0.6117647  0.59607846 0.50980395]\n",
      "   [0.62352943 0.6313726  0.5568628 ]\n",
      "   ...\n",
      "   [0.40392157 0.3647059  0.3764706 ]\n",
      "   [0.48235294 0.44705883 0.47058824]\n",
      "   [0.5137255  0.4745098  0.5137255 ]]\n",
      "\n",
      "  [[0.6392157  0.5803922  0.47058824]\n",
      "   [0.61960787 0.5803922  0.47843137]\n",
      "   [0.6392157  0.6117647  0.52156866]\n",
      "   ...\n",
      "   [0.56078434 0.52156866 0.54509807]\n",
      "   [0.56078434 0.5254902  0.5568628 ]\n",
      "   [0.56078434 0.52156866 0.5647059 ]]]\n",
      "\n",
      "\n",
      " [[[1.         1.         1.        ]\n",
      "   [0.99215686 0.99215686 0.99215686]\n",
      "   [0.99215686 0.99215686 0.99215686]\n",
      "   ...\n",
      "   [0.99215686 0.99215686 0.99215686]\n",
      "   [0.99215686 0.99215686 0.99215686]\n",
      "   [0.99215686 0.99215686 0.99215686]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]\n",
      "   [1.         1.         1.        ]]\n",
      "\n",
      "  [[1.         1.         1.        ]\n",
      "   [0.99607843 0.99607843 0.99607843]\n",
      "   [0.99607843 0.99607843 0.99607843]\n",
      "   ...\n",
      "   [0.99607843 0.99607843 0.99607843]\n",
      "   [0.99607843 0.99607843 0.99607843]\n",
      "   [0.99607843 0.99607843 0.99607843]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.44313726 0.47058824 0.4392157 ]\n",
      "   [0.43529412 0.4627451  0.43529412]\n",
      "   [0.4117647  0.4392157  0.41568628]\n",
      "   ...\n",
      "   [0.28235295 0.31764707 0.3137255 ]\n",
      "   [0.28235295 0.3137255  0.30980393]\n",
      "   [0.28235295 0.3137255  0.30980393]]\n",
      "\n",
      "  [[0.43529412 0.4627451  0.43137255]\n",
      "   [0.40784314 0.43529412 0.40784314]\n",
      "   [0.3882353  0.41568628 0.38431373]\n",
      "   ...\n",
      "   [0.26666668 0.29411766 0.28627452]\n",
      "   [0.27450982 0.29803923 0.29411766]\n",
      "   [0.30588236 0.32941177 0.32156864]]\n",
      "\n",
      "  [[0.41568628 0.44313726 0.4117647 ]\n",
      "   [0.3882353  0.41568628 0.38431373]\n",
      "   [0.37254903 0.4        0.36862746]\n",
      "   ...\n",
      "   [0.30588236 0.33333334 0.3254902 ]\n",
      "   [0.30980393 0.33333334 0.3254902 ]\n",
      "   [0.3137255  0.3372549  0.32941177]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.13725491 0.69803923 0.92156863]\n",
      "   [0.15686275 0.6901961  0.9372549 ]\n",
      "   [0.16470589 0.6901961  0.94509804]\n",
      "   ...\n",
      "   [0.3882353  0.69411767 0.85882354]\n",
      "   [0.30980393 0.5764706  0.77254903]\n",
      "   [0.34901962 0.5803922  0.7411765 ]]\n",
      "\n",
      "  [[0.22352941 0.7137255  0.91764706]\n",
      "   [0.17254902 0.72156864 0.98039216]\n",
      "   [0.19607843 0.7176471  0.9411765 ]\n",
      "   ...\n",
      "   [0.6117647  0.7137255  0.78431374]\n",
      "   [0.5529412  0.69411767 0.80784315]\n",
      "   [0.45490196 0.58431375 0.6862745 ]]\n",
      "\n",
      "  [[0.38431373 0.77254903 0.92941177]\n",
      "   [0.2509804  0.7411765  0.9882353 ]\n",
      "   [0.27058825 0.7529412  0.9607843 ]\n",
      "   ...\n",
      "   [0.7372549  0.7647059  0.80784315]\n",
      "   [0.46666667 0.5294118  0.5764706 ]\n",
      "   [0.23921569 0.30980393 0.3529412 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.28627452 0.30980393 0.3019608 ]\n",
      "   [0.20784314 0.24705882 0.26666668]\n",
      "   [0.21176471 0.26666668 0.3137255 ]\n",
      "   ...\n",
      "   [0.06666667 0.15686275 0.2509804 ]\n",
      "   [0.08235294 0.14117648 0.2       ]\n",
      "   [0.12941177 0.1882353  0.19215687]]\n",
      "\n",
      "  [[0.23921569 0.26666668 0.29411766]\n",
      "   [0.21568628 0.27450982 0.3372549 ]\n",
      "   [0.22352941 0.30980393 0.40392157]\n",
      "   ...\n",
      "   [0.09411765 0.1882353  0.28235295]\n",
      "   [0.06666667 0.13725491 0.20784314]\n",
      "   [0.02745098 0.09019608 0.1254902 ]]\n",
      "\n",
      "  [[0.17254902 0.21960784 0.28627452]\n",
      "   [0.18039216 0.25882354 0.34509805]\n",
      "   [0.19215687 0.3019608  0.4117647 ]\n",
      "   ...\n",
      "   [0.10588235 0.20392157 0.3019608 ]\n",
      "   [0.08235294 0.16862746 0.25882354]\n",
      "   [0.04705882 0.12156863 0.19607843]]]\n",
      "\n",
      "\n",
      " [[[0.7411765  0.827451   0.9411765 ]\n",
      "   [0.7294118  0.8156863  0.9254902 ]\n",
      "   [0.7254902  0.8117647  0.92156863]\n",
      "   ...\n",
      "   [0.6862745  0.7647059  0.8784314 ]\n",
      "   [0.6745098  0.7607843  0.87058824]\n",
      "   [0.6627451  0.7607843  0.8627451 ]]\n",
      "\n",
      "  [[0.7607843  0.8235294  0.9372549 ]\n",
      "   [0.7490196  0.8117647  0.9254902 ]\n",
      "   [0.74509805 0.80784315 0.92156863]\n",
      "   ...\n",
      "   [0.6784314  0.7529412  0.8627451 ]\n",
      "   [0.67058825 0.7490196  0.85490197]\n",
      "   [0.654902   0.74509805 0.84705883]]\n",
      "\n",
      "  [[0.8156863  0.85882354 0.95686275]\n",
      "   [0.8039216  0.84705883 0.9411765 ]\n",
      "   [0.8        0.84313726 0.9372549 ]\n",
      "   ...\n",
      "   [0.6862745  0.7490196  0.8509804 ]\n",
      "   [0.6745098  0.74509805 0.84705883]\n",
      "   [0.6627451  0.7490196  0.84313726]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8117647  0.78039217 0.70980394]\n",
      "   [0.79607844 0.7647059  0.6862745 ]\n",
      "   [0.79607844 0.76862746 0.6784314 ]\n",
      "   ...\n",
      "   [0.5294118  0.5176471  0.49803922]\n",
      "   [0.63529414 0.61960787 0.5882353 ]\n",
      "   [0.65882355 0.6392157  0.5921569 ]]\n",
      "\n",
      "  [[0.7764706  0.74509805 0.6666667 ]\n",
      "   [0.7411765  0.70980394 0.62352943]\n",
      "   [0.7058824  0.6745098  0.5764706 ]\n",
      "   ...\n",
      "   [0.69803923 0.67058825 0.627451  ]\n",
      "   [0.6862745  0.6627451  0.6117647 ]\n",
      "   [0.6862745  0.6627451  0.6039216 ]]\n",
      "\n",
      "  [[0.7764706  0.7411765  0.6784314 ]\n",
      "   [0.7411765  0.70980394 0.63529414]\n",
      "   [0.69803923 0.6666667  0.58431375]\n",
      "   ...\n",
      "   [0.7647059  0.72156864 0.6627451 ]\n",
      "   [0.76862746 0.7411765  0.67058825]\n",
      "   [0.7647059  0.74509805 0.67058825]]]\n",
      "\n",
      "\n",
      " [[[0.8980392  0.8980392  0.9372549 ]\n",
      "   [0.9254902  0.92941177 0.96862745]\n",
      "   [0.91764706 0.9254902  0.96862745]\n",
      "   ...\n",
      "   [0.8509804  0.85882354 0.9137255 ]\n",
      "   [0.8666667  0.8745098  0.91764706]\n",
      "   [0.87058824 0.8745098  0.9137255 ]]\n",
      "\n",
      "  [[0.87058824 0.8666667  0.8980392 ]\n",
      "   [0.9372549  0.9372549  0.9764706 ]\n",
      "   [0.9137255  0.91764706 0.9647059 ]\n",
      "   ...\n",
      "   [0.8745098  0.8745098  0.9254902 ]\n",
      "   [0.8901961  0.89411765 0.93333334]\n",
      "   [0.8235294  0.827451   0.8627451 ]]\n",
      "\n",
      "  [[0.8352941  0.80784315 0.827451  ]\n",
      "   [0.91764706 0.9098039  0.9372549 ]\n",
      "   [0.90588236 0.9137255  0.95686275]\n",
      "   ...\n",
      "   [0.8627451  0.8627451  0.9098039 ]\n",
      "   [0.8627451  0.85882354 0.9098039 ]\n",
      "   [0.7921569  0.79607844 0.84313726]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5882353  0.56078434 0.5294118 ]\n",
      "   [0.54901963 0.5294118  0.49803922]\n",
      "   [0.5176471  0.49803922 0.47058824]\n",
      "   ...\n",
      "   [0.8784314  0.87058824 0.85490197]\n",
      "   [0.9019608  0.89411765 0.88235295]\n",
      "   [0.94509804 0.94509804 0.93333334]]\n",
      "\n",
      "  [[0.5372549  0.5176471  0.49411765]\n",
      "   [0.50980395 0.49803922 0.47058824]\n",
      "   [0.49019608 0.4745098  0.4509804 ]\n",
      "   ...\n",
      "   [0.70980394 0.7058824  0.69803923]\n",
      "   [0.7921569  0.7882353  0.7764706 ]\n",
      "   [0.83137256 0.827451   0.8117647 ]]\n",
      "\n",
      "  [[0.47843137 0.46666667 0.44705883]\n",
      "   [0.4627451  0.45490196 0.43137255]\n",
      "   [0.47058824 0.45490196 0.43529412]\n",
      "   ...\n",
      "   [0.7019608  0.69411767 0.6784314 ]\n",
      "   [0.6431373  0.6431373  0.63529414]\n",
      "   [0.6392157  0.6392157  0.6313726 ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db0b54e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(32, 32, 3)), #we are not going to flatten it because we are using CNN\n",
    "        layers.Conv2D(32, 3, padding='valid', activation='relu'), #32 out channels is how many channel we want this layer to output, \n",
    "                             #in the begining we had 3 and now we want their output to be 32,\n",
    "                             #then kernel size = 3, means (3,3), padding valid id default\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        layers.Conv2D(64, 3,  activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, 3,  activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64,  activation='relu'),\n",
    "        layers.Dense(10)\n",
    "    ]\n",
    ")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c24eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24a993cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 - 30s - loss: 1.7024 - accuracy: 0.3817\n",
      "Epoch 2/10\n",
      "782/782 - 30s - loss: 1.3541 - accuracy: 0.5168\n",
      "Epoch 3/10\n",
      "782/782 - 29s - loss: 1.2263 - accuracy: 0.5690\n",
      "Epoch 4/10\n",
      "782/782 - 22s - loss: 1.1277 - accuracy: 0.6048\n",
      "Epoch 5/10\n",
      "782/782 - 27s - loss: 1.0525 - accuracy: 0.6336\n",
      "Epoch 6/10\n",
      "782/782 - 30s - loss: 0.9911 - accuracy: 0.6556\n",
      "Epoch 7/10\n",
      "782/782 - 32s - loss: 0.9342 - accuracy: 0.6767\n",
      "Epoch 8/10\n",
      "782/782 - 39s - loss: 0.8935 - accuracy: 0.6904\n",
      "Epoch 9/10\n",
      "782/782 - 33s - loss: 0.8490 - accuracy: 0.7063\n",
      "Epoch 10/10\n",
      "782/782 - 30s - loss: 0.8063 - accuracy: 0.7222\n",
      "157/157 - 2s - loss: 0.9443 - accuracy: 0.6722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9443255066871643, 0.6722000241279602]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=64, epochs=10, verbose=2)\n",
    "model.evaluate(x_test,y_test,batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f064d1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
